<!doctype html><html>
<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <title>4.2.1 Conduct Search Engine Discovery and Reconnaissance for Information Leakage (OTG-INFO-001) </title>
  <meta name="generator" content="CherryTree">
  <link rel="stylesheet" href="res/styles3.css" type="text/css" />
  
    <script type="text/javascript">
        function in_frame () { try { return window.self !== window.top; } catch (e) { return true; } }
        if (!in_frame()) {
            var page = location.pathname.substring(location.pathname.lastIndexOf("/") + 1);
            window.location = 'index.html#' + page;
        }
    </script>
</head>
<body><div class="page"><h1 class="title">4.2.1 Conduct Search Engine Discovery and Reconnaissance for Information Leakage (OTG-INFO-001) </h1><br/><h2>Summary</h2><br />There are direct and indirect elements to search engine discovery and  reconnaissance. Direct methods relate to searching the indexes and the  associated content from caches. Indirect methods relate to gleaning  sensitive design and configuration information by searching forums,  newsgroups, and tendering websites. <br /><br /> Once a search engine robot has completed crawling, it commences indexing  the web page based on tags and associated attributes, such as  &lt;TITLE&gt;, in order to return the relevant search results [1]. If  the robots.txt file is not updated during the lifetime of the web site,  and inline HTML meta tags that instruct robots not to index content have  not been used, then it is possible for indexes to contain web content  not intended to be included in by the owners. Website owners may use the  previously mentioned robots.txt, HTML meta tags, authentication, and  tools provided by search engines to remove such content. <br /><br /> <h2>Test Objectives</h2><br />To understand what sensitive design and configuration information of  the application/system/organization is exposed both directly (on the  organization's website) or indirectly (on a third party website). <br /><br /><h2>How to Test</h2><br />Use a search engine to search for: <br />•  Network diagrams and configurations<br />•  Archived posts and emails by administrators and other key staff<br />•  Log on procedures and username formats<br />•  Usernames and passwords<br />•  Error message content<br />•  Development, test, UAT and staging versions of the website<br /><br /> <br /><br /><h3>Search operators</h3><br />Using the advanced "site:" search operator, it is possible to  restrict search results to a specific domain [2]. Do not limit testing  to just one search engine provider as they may generate different  results depending on when they crawled content and their own algorithms.  Consider using the following search engines: <br />•  Baidu<br />•  binsearch.info<br />•  Bing<br />•  Duck Duck Go<br />•  ixquick/Startpage<br />•  Google<br />•  Shodan<br />•  PunkSpider<br /><br /> Duck Duck Go and ixquick/Startpage provide reduced information leakage about the tester. <br />Google provides the Advanced "cache:" search operator [2], but  this is the equivalent to clicking the "Cached" next to each Google  Search Result.  Hence, the use of the Advanced "site:" Search Operator  and then clicking "Cached" is preferred.  <br />The Google SOAP Search API supports the doGetCachedPage and the  associated doGetCachedPageResponse SOAP Messages [3] to assist with  retrieving cached pages. An implementation of this is under development  by the <a href="https://www.owasp.org/index.php/Category:OWASP_Google_Hacking_Project">OWASP "Google Hacking" Project</a>. <br />PunkSpider is web application vulnerability search engine. It is  of little use for a penetration tester doing manual work. However it can  be useful as demonstration of easiness of finding vulnerabilities by  script-kiddies. <br /><br /> <strong>Example</strong> To find the web content of owasp.org indexed by a typical search engine, the syntax required is: <br />site:owasp.org<br /><img src="images/176-1.png" alt="images/176-1.png" /> <br />To display the index.html of owasp.org as cached, the syntax is: <br />cache:owasp.org<br /><img src="images/176-2.png" alt="images/176-2.png" /> <br /><br /> <br /><br /><h3>Google Hacking Database</h3><br />The Google Hacking Database is list of useful search queries for Google. Queries are put in several categories: <br />•  Footholds<br />•  Files containing usernames<br />•  Sensitive Directories<br />•  Web Server Detection<br />•  Vulnerable Files<br />•  Vulnerable Servers<br />•  Error Messages<br />•  Files containing juicy info<br />•  Files containing passwords<br />•  Sensitive Online Shopping Info<br /><br /> <br /><br /><h2>Tools</h2><br />[4] FoundStone SiteDigger - <a href="http://www.mcafee.com/uk/downloads/free-tools/sitedigger.aspx">http://www.mcafee.com/uk/downloads/free-tools/sitedigger.aspx</a> <br /> [5] Google Hacker - <a href="http://yehg.net/lab/pr0js/files.php/googlehacker.zip">http://yehg.net/lab/pr0js/files.php/googlehacker.zip</a><br /> [6] Bishop Fox's Google Hacking Diggity Project - <a href="http://www.bishopfox.com/resources/tools/google-hacking-diggity/">http://www.bishopfox.com/resources/tools/google-hacking-diggity/</a> <br /> [7] PunkSPIDER - <a href="http://punkspider.hyperiongray.com/">http://punkspider.hyperiongray.com/</a> <br /> <br /><br /> <br /><br /><h2>References</h2><br /><strong>Web</strong><br /> [1] "Google Basics: Learn how Google Discovers, Crawls, and Serves Web Pages" - <a href="https://support.google.com/webmasters/answer/70897">https://support.google.com/webmasters/answer/70897</a> <br /> [2] "Operators and More Search Help" - <a href="https://support.google.com/websearch/answer/136861?hl=en">https://support.google.com/websearch/answer/136861?hl=en</a> <br /> [3] "Google Hacking Database" - <a href="http://www.exploit-db.com/google-dorks/">http://www.exploit-db.com/google-dorks/</a><br /></div></body></html>